{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac206671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze(filepath):\n",
    "    #Initial print\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"Analyzing: {os.path.basename(filepath)}\")\n",
    "    print('='*30)\n",
    "\n",
    "    # Mesh loading\n",
    "    mesh = trimesh.load(filepath)\n",
    "    vertices = np.array(mesh.vertices)  \n",
    "    faces = np.array(mesh.faces)\n",
    "        \n",
    "    num_vertices = vertices.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "    \n",
    "    print(f\"Number of vertices: {num_vertices}\")\n",
    "    print(f\"Number of faces: {num_faces}\")\n",
    "    \n",
    "    #per-axis statistics\n",
    "    axis_names = np.array(['X', 'Y', 'Z'])\n",
    "    mins = np.min(vertices, axis=0)\n",
    "    maxs = np.max(vertices, axis=0)\n",
    "    means = np.mean(vertices, axis=0)\n",
    "    stds = np.std(vertices, axis=0)\n",
    "        \n",
    "    for i, axis in enumerate(axis_names):\n",
    "        print(f\"\\n{axis}-axis:\")\n",
    "        print(f\"  Min: {mins[i]:.4f}\")\n",
    "        print(f\"  Max: {maxs[i]:.4f}\")\n",
    "        print(f\"  Mean: {means[i]:.4f}\")\n",
    "        print(f\"  Std Dev: {stds[i]:.4f}\")\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\nBounding box dimensions:\")\n",
    "    bbox_dims = maxs - mins\n",
    "    print(f\"Width (X): {bbox_dims[0]:.4f}\")\n",
    "    print(f\"Depth (Y): {bbox_dims[1]:.4f}\")\n",
    "    print(f\"Height (Z): {bbox_dims[2]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nMesh centroid: ({means[0]:.4f}, {means[1]:.4f}, {means[2]:.4f})\")\n",
    "    \n",
    "    # Visualization                                \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    ax.plot_trisurf(vertices[:, 0], vertices[:, 1], vertices[:, 2], triangles=faces, cmap='viridis', alpha=0.8, edgecolor='none')\n",
    "    \n",
    "    ax.set_title(f'{os.path.basename(filepath)}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mesh, vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = \"meshes/\"\n",
    "mesh_samples = np.array([i for i in os.listdir(meshes) if i.endswith('.obj')])\n",
    "\n",
    "print(f\"Found {len(mesh_samples)} sample mesh files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471547a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_filename in mesh_samples:\n",
    "    filepath = os.path.join(meshes, sample_filename)\n",
    "    mesh, vertices = load_and_analyze(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438611f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BINS = 1024\n",
    "OUTPUT_ROOT = \"Outputs\"\n",
    "MESH_DIR = \"meshes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_normalize(vertices):\n",
    "    \"\"\"\n",
    "    Min–Max Normalization: Scale vertex coordinates into [0, 1] per axis.\n",
    "    \"\"\"\n",
    "    v_min = vertices.min(axis=0)\n",
    "    v_max = vertices.max(axis=0)\n",
    "    # prevent divide-by-zero\n",
    "    range_ = v_max - v_min\n",
    "    range_[range_ == 0] = 1.0\n",
    "    normalized = (vertices - v_min) / range_\n",
    "    return normalized, v_min, v_max\n",
    "\n",
    "def unit_sphere_normalize(vertices):\n",
    "    \"\"\"\n",
    "    Unit Sphere Normalization: Center vertices and scale so that \n",
    "    the farthest vertex lies on a unit sphere (‖v‖ ≤ 1).\n",
    "    \"\"\"\n",
    "    centroid = vertices.mean(axis=0)\n",
    "    centered = vertices - centroid\n",
    "    scale = np.max(np.linalg.norm(centered, axis=1))\n",
    "    if scale == 0: \n",
    "        scale = 1.0\n",
    "    normalized = centered / scale\n",
    "    return normalized, centroid, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(normalized, bins=1024):\n",
    "    \"\"\"\n",
    "    Discretize normalized coordinates into bins.\n",
    "    If normalization range is [-1, 1], first map to [0, 1].\n",
    "    \"\"\"\n",
    "    norm_copy = normalized.copy()\n",
    "    if norm_copy.min() < 0:\n",
    "        norm_copy = (norm_copy + 1) / 2  # shift [-1,1] → [0,1]\n",
    "    norm_copy = np.clip(norm_copy, 0, 1)\n",
    "    quantized = np.floor(norm_copy * (bins - 1)).astype(np.int32)\n",
    "    return quantized\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e205c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_task2(norm_mm, norm_us, quant_mm, quant_us, faces, sample_name, sample_dir):\n",
    "    \"\"\"\n",
    "    Generateing a 2×2 subplot for each mesh:\n",
    "    Row 1: Min–Max Normalized | Unit Sphere Normalized\n",
    "    Row 2: Min–Max Quantized  | Unit Sphere Quantized\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import numpy as np, os\n",
    "\n",
    "    # #Downsample for speed\n",
    "    # def maybe_downsample(verts, max_verts=8000):\n",
    "    #     if len(verts) > max_verts:\n",
    "    #         idx = np.random.choice(len(verts), max_verts, replace=False)\n",
    "    #         return verts[idx]\n",
    "    #     return verts\n",
    "    \"\"\" Removed the downsampling function and passing the values as it is.\"\"\"\n",
    "    norm_mm_vis = norm_mm\n",
    "    norm_us_vis = norm_us\n",
    "    quant_mm_vis =quant_mm.astype(float)\n",
    "    quant_us_vis =quant_us.astype(float)\n",
    "\n",
    "    # --- Create figure ---\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 12), subplot_kw={'projection': '3d'})\n",
    "    fig.suptitle(f'Task 2 Results: {sample_name}', fontsize=15, fontweight='bold')\n",
    "\n",
    "    \n",
    "    def set_equal_axes(ax, data):\n",
    "        mins, maxs = data.min(axis=0), data.max(axis=0)\n",
    "        rng = maxs - mins\n",
    "        mid = (maxs + mins) / 2\n",
    "        max_range = rng.max() / 2\n",
    "        ax.set_xlim(mid[0]-max_range, mid[0]+max_range)\n",
    "        ax.set_ylim(mid[1]-max_range, mid[1]+max_range)\n",
    "        ax.set_zlim(mid[2]-max_range, mid[2]+max_range)\n",
    "\n",
    "  \n",
    "    plots = [\n",
    "        (axs[0,0], norm_mm_vis, 'Min–Max Normalized', 'skyblue'),\n",
    "        (axs[0,1], norm_us_vis, 'Unit Sphere Normalized', 'lightgreen'),\n",
    "        (axs[1,0], quant_mm_vis, 'Min–Max Quantized', 'orange'),\n",
    "        (axs[1,1], quant_us_vis, 'Unit Sphere Quantized', 'pink')\n",
    "    ]\n",
    "\n",
    "    for ax, data, title, color in plots:\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2], s=5, c=color, alpha=0.7)\n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "        set_equal_axes(ax, data)\n",
    "        ax.grid(False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    " \n",
    "    plot_path = os.path.join(sample_dir, \"plots\", \"task2_results.png\")\n",
    "    os.makedirs(os.path.dirname(plot_path), exist_ok=True)\n",
    "    plt.savefig(plot_path, dpi=200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Visualization saved {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca093322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_task2(mesh_path, sample_name):\n",
    "    \"\"\"\n",
    "    Process a single mesh for Task 2:\n",
    "    1. Load mesh\n",
    "    2. Apply both normalization methods\n",
    "    3. Quantize both\n",
    "    4. Save all four meshes (.ply)\n",
    "    5. Generate visualization\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {sample_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load mesh\n",
    "    mesh = trimesh.load(mesh_path, process=False)\n",
    "    vertices = np.array(mesh.vertices)\n",
    "    faces = np.array(mesh.faces)\n",
    "    \n",
    "    print(f\"Vertices: {len(vertices)}, Faces: {len(faces)}\")\n",
    "    \n",
    "    # Apply both normalization methods\n",
    "    print(\"\\n[1] Normalizing...\")\n",
    "    norm_mm, vmin, vmax = minmax_normalize(vertices)\n",
    "    norm_us, centroid, scale = unit_sphere_normalize(vertices)\n",
    "    print(f\" Min–Max range: [{norm_mm.min():.3f}, {norm_mm.max():.3f}]\")\n",
    "    print(f\" Unit Sphere range: [{norm_us.min():.3f}, {norm_us.max():.3f}]\")\n",
    "\n",
    "    # Making sure to save all these vmin,vmax,norm_us, etc in a json file for future use in task 3.\n",
    "    sample_dir = os.path.join(OUTPUT_ROOT, sample_name)\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    params = {\n",
    "        \"vmin\": vmin.tolist(),\n",
    "        \"vmax\": vmax.tolist(),\n",
    "        \"centroid\": centroid.tolist(),\n",
    "        \"scale\": float(scale),\n",
    "        \"bins\": BINS,\n",
    "        \"shifted_mm\": False,   # Min–Max normalization already in [0,1]\n",
    "        \"shifted_us\": True    # Unit Sphere normalization mapped from [-1,1] → [0,1]\n",
    "        }             \n",
    "\n",
    "    params_path = os.path.join(sample_dir, \"normalization_params.json\")\n",
    "    \n",
    "    with open(params_path, \"w\") as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "        print(f\"  ✓ Saved normalization parameters: {params_path}\")\n",
    "    \n",
    "    # Quantize both\n",
    "    print(f\"\\n[2] Quantizing with {BINS} bins...\")\n",
    "    quant_mm = quantize(norm_mm, bins=BINS)\n",
    "    quant_us = quantize(norm_us, bins=BINS)\n",
    "    print(f\" Min–Max quantized: [{quant_mm.min()}, {quant_mm.max()}]\")\n",
    "    print(f\" Unit Sphere quantized: [{quant_us.min()}, {quant_us.max()}]\")\n",
    "    \n",
    "    # Create output directories\n",
    "    sample_dir = os.path.join(OUTPUT_ROOT, sample_name)\n",
    "    os.makedirs(os.path.join(sample_dir, \"normalized\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(sample_dir, \"quantized\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(sample_dir, \"plots\"), exist_ok=True)\n",
    "    \n",
    "    # Save all four meshes\n",
    "    print(\"\\n[3] Saving meshes...\")\n",
    "    trimesh.Trimesh(norm_mm, faces, process=False).export(\n",
    "        os.path.join(sample_dir, \"normalized\", \"minmax.ply\"))\n",
    "    trimesh.Trimesh(norm_us, faces, process=False).export(\n",
    "        os.path.join(sample_dir, \"normalized\", \"unitsphere.ply\"))\n",
    "    trimesh.Trimesh(quant_mm.astype(float), faces, process=False).export(\n",
    "        os.path.join(sample_dir, \"quantized\", \"minmax.ply\"))\n",
    "    trimesh.Trimesh(quant_us.astype(float), faces, process=False).export(\n",
    "        os.path.join(sample_dir, \"quantized\", \"unitsphere.ply\"))\n",
    "    \n",
    "    print(f\"  ✓ Saved normalized meshes: {sample_dir}/normalized/\")\n",
    "    print(f\"  ✓ Saved quantized meshes: {sample_dir}/quantized/\")\n",
    "    \n",
    "    # Generate visualization\n",
    "    print(\"\\n[4] Creating visualization...\")\n",
    "    visualize_task2(norm_mm, norm_us, quant_mm, quant_us, faces, sample_name, sample_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Completed: {sample_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_meshes():\n",
    "    \"\"\"\n",
    "    Loop through all meshes in the dataset and process each for Task 2.\n",
    "    \"\"\"\n",
    "    # Find all .obj files in MESH_DIR\n",
    "    mesh_files = [f for f in os.listdir(MESH_DIR) if f.endswith('.obj')]\n",
    "    \n",
    "    if not mesh_files:\n",
    "        print(f\"No .obj files found in {MESH_DIR}/\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TASK 2: NORMALIZE & QUANTIZE MESHES\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Found {len(mesh_files)} mesh file(s)\")\n",
    "    print(f\"Output directory: {OUTPUT_ROOT}/\")\n",
    "    print(f\"Bins: {BINS}\")\n",
    "    \n",
    "    # Process each mesh\n",
    "    for mesh_file in mesh_files:\n",
    "        mesh_path = os.path.join(MESH_DIR, mesh_file)\n",
    "        sample_name = os.path.splitext(mesh_file)[0]\n",
    "\n",
    "        \n",
    "        try:\n",
    "            process_mesh_task2(mesh_path, sample_name)  \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ ERROR processing {mesh_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TASK 2 COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n Deliverables for each mesh:\")\n",
    "    print(f\"   • normalized/minmax.ply\")\n",
    "    print(f\"   • normalized/unitsphere.ply\")\n",
    "    print(f\"   • quantized/minmax.ply\")\n",
    "    print(f\"   • quantized/unitsphere.ply\")\n",
    "    print(f\"   • plots/task2_results.png\")\n",
    "    print(f\"\\n{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14003605",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_all_meshes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a567d9",
   "metadata": {},
   "source": [
    "Normalization is done to put the mesh in a common scale so that it can be better processed. The 2 such way to perform normalization on a mesh are as follows:-\n",
    "\n",
    "1. Min-max Normalization\n",
    "\n",
    "In Min-max we take the minimum and the maximum points in each axis x,y,z and create a box of 0 to 1 to squash these mesh coordinates in the box. Using min-max usually distorts the mesh structure as it needs to put all the coordinates into this box. Hence mesh structure is NOT preserved.\n",
    "\n",
    "2. Unit Sphere Normalization\n",
    "\n",
    "In Unit-Sphere we take a center point in the mesh and create a sphere. We then try to shrink the mesh structer uniformaly such that the farthest vertex is on the surface of the sphere radius=1. The structure is preserved and normalization is also achieved. Hence mesh structure is preserved and Normalization is achieved.\n",
    "\n",
    "-> Unit Sphere Normalization preserves the Mesh Structure and Normalize the mesh at the same time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d37e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_minmax(dequantized, vmin, vmax):\n",
    "    \"\"\"Denormalize Min-Max back to original scale.\"\"\"\n",
    "    return dequantized * (vmax - vmin) + vmin\n",
    "\n",
    "def denormalize_unitsphere(dequantized, centroid, scale):\n",
    "    \"\"\"Denormalize Unit Sphere back to original scale.\"\"\"\n",
    "    return dequantized * scale + centroid\n",
    "\n",
    "def dequantize(quantized, bins=1024, shifted=False):\n",
    "    \"\"\"Dequantize back to normalized coordinates.\"\"\"\n",
    "    dequantized = quantized.astype(float) / (bins - 1)\n",
    "    if shifted:\n",
    "        dequantized = dequantized * 2 - 1  # shift back [0,1] → [-1,1]\n",
    "    return dequantized\n",
    "\n",
    "def compute_errors(original, reconstructed):\n",
    "    \"\"\"Compute reconstruction error metrics.\"\"\"\n",
    "    mse = np.mean((original - reconstructed) ** 2)\n",
    "    mae = np.mean(np.abs(original - reconstructed))\n",
    "    mse_axis = np.mean((original - reconstructed) ** 2, axis=0)\n",
    "    mae_axis = np.mean(np.abs(original - reconstructed), axis=0)\n",
    "    \n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"mae\": mae,\n",
    "        \"mse_axis\": mse_axis,\n",
    "        \"mae_axis\": mae_axis\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(original, recon_mm, recon_us, sample_name, sample_dir):\n",
    "    \"\"\"Visualize original vs reconstructed meshes (1×3 layout).\"\"\"\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6), subplot_kw={'projection': '3d'})\n",
    "    fig.suptitle(f'Task 3: Reconstruction - {sample_name}', fontsize=15, fontweight='bold')\n",
    "    \n",
    "    def set_equal_axes(ax, data):\n",
    "        mins, maxs = data.min(axis=0), data.max(axis=0)\n",
    "        rng = maxs - mins\n",
    "        mid = (maxs + mins) / 2\n",
    "        max_range = rng.max() / 2\n",
    "        ax.set_xlim(mid[0]-max_range, mid[0]+max_range)\n",
    "        ax.set_ylim(mid[1]-max_range, mid[1]+max_range)\n",
    "        ax.set_zlim(mid[2]-max_range, mid[2]+max_range)\n",
    "    \n",
    "    plots = [\n",
    "        (axs[0], original, 'Original', 'gray'),\n",
    "        (axs[1], recon_mm, 'Min–Max Reconstructed', 'green'),\n",
    "        (axs[2], recon_us, 'Unit Sphere Reconstructed', 'blue')\n",
    "    ]\n",
    "    \n",
    "    for ax, data, title, color in plots:\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2], s=5, c=color, alpha=0.7)\n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')\n",
    "        set_equal_axes(ax, data)\n",
    "        ax.grid(False)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plot_path = os.path.join(sample_dir, \"plots\", \"task3_reconstruction.png\")\n",
    "    plt.savefig(plot_path, dpi=200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"  ✓ Reconstruction visualization saved: {plot_path}\")\n",
    "\n",
    "def plot_error_per_axis(errors_mm, errors_us, sample_name, sample_dir):\n",
    "    \"\"\"Plot reconstruction error per axis (bar chart).\"\"\"\n",
    "    axes_labels = ['X', 'Y', 'Z']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    fig.suptitle(f'Task 3: Reconstruction Error per Axis - {sample_name}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # MSE per axis\n",
    "    x = np.arange(len(axes_labels))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, errors_mm['mse_axis'], width, label='Min–Max', \n",
    "            alpha=0.8, color='green')\n",
    "    ax1.bar(x + width/2, errors_us['mse_axis'], width, label='Unit Sphere', \n",
    "            alpha=0.8, color='blue')\n",
    "    ax1.set_xlabel('Axis')\n",
    "    ax1.set_ylabel('MSE')\n",
    "    ax1.set_title('Mean Squared Error per Axis')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(axes_labels)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # MAE per axis\n",
    "    ax2.bar(x - width/2, errors_mm['mae_axis'], width, label='Min–Max', \n",
    "            alpha=0.8, color='green')\n",
    "    ax2.bar(x + width/2, errors_us['mae_axis'], width, label='Unit Sphere', \n",
    "            alpha=0.8, color='blue')\n",
    "    ax2.set_xlabel('Axis')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_title('Mean Absolute Error per Axis')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(axes_labels)\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plot_path = os.path.join(sample_dir, \"plots\", \"task3_error_plot.png\")\n",
    "    plt.savefig(plot_path, dpi=200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"  ✓ Error plot saved: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mesh_task3(mesh_path, sample_name):\n",
    "    \"\"\"Process a single mesh for Task 3: Dequantize, Denormalize, Measure Error.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Task 3 Processing: {sample_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    sample_dir = os.path.join(OUTPUT_ROOT, sample_name)\n",
    "    \n",
    "    # STEP 2 — Load required data\n",
    "    print(\"\\n[1] Loading data...\")\n",
    "    \n",
    "    # Load original mesh\n",
    "    mesh = trimesh.load(mesh_path, process=False)\n",
    "    original_vertices = np.array(mesh.vertices)\n",
    "    print(f\"  ✓ Loaded original: {len(original_vertices)} vertices\")\n",
    "    \n",
    "    # Load normalization parameters\n",
    "    params_path = os.path.join(sample_dir, \"normalization_params.json\")\n",
    "    if not os.path.exists(params_path):\n",
    "        print(f\"  ✗ Parameters not found: {params_path}\")\n",
    "        return None\n",
    "    \n",
    "    with open(params_path, 'r') as f:\n",
    "        params = json.load(f)\n",
    "    \n",
    "    vmin = np.array(params['vmin'])\n",
    "    vmax = np.array(params['vmax'])\n",
    "    centroid = np.array(params['centroid'])\n",
    "    scale = params['scale']\n",
    "    bins = params['bins']\n",
    "    shifted_mm = params['shifted_mm']\n",
    "    shifted_us = params['shifted_us']\n",
    "    print(f\"  ✓ Loaded normalization parameters\")\n",
    "    \n",
    "    # Load quantized meshes\n",
    "    quant_mm_mesh = trimesh.load(\n",
    "        os.path.join(sample_dir, \"quantized\", \"minmax.ply\"), process=False)\n",
    "    quant_us_mesh = trimesh.load(\n",
    "        os.path.join(sample_dir, \"quantized\", \"unitsphere.ply\"), process=False)\n",
    "    \n",
    "    quant_mm = np.array(quant_mm_mesh.vertices)\n",
    "    quant_us = np.array(quant_us_mesh.vertices)\n",
    "    print(f\"  ✓ Loaded quantized meshes\")\n",
    "    \n",
    "    # STEP 3 — Dequantize\n",
    "    print(\"\\n[2] Dequantizing...\")\n",
    "    dequant_mm = dequantize(quant_mm.astype(int), bins=bins, shifted=shifted_mm)\n",
    "    dequant_us = dequantize(quant_us.astype(int), bins=bins, shifted=shifted_us)\n",
    "    print(f\"  ✓ Dequantized both meshes\")\n",
    "    \n",
    "    # STEP 4 — Denormalize to original scale\n",
    "    print(\"\\n[3] Denormalizing to original scale...\")\n",
    "    recon_mm = denormalize_minmax(dequant_mm, vmin, vmax)\n",
    "    recon_us = denormalize_unitsphere(dequant_us, centroid, scale)\n",
    "    print(f\"  ✓ Reconstructed Min–Max mesh\")\n",
    "    print(f\"  ✓ Reconstructed Unit Sphere mesh\")\n",
    "    \n",
    "    # STEP 5 — Compute reconstruction errors\n",
    "    print(\"\\n[4] Computing reconstruction errors...\")\n",
    "    errors_mm = compute_errors(original_vertices, recon_mm)\n",
    "    errors_us = compute_errors(original_vertices, recon_us)\n",
    "    \n",
    "    print(f\"\\n  Min–Max Errors:\")\n",
    "    print(f\"    MSE: {errors_mm['mse']:.8f}\")\n",
    "    print(f\"    MAE: {errors_mm['mae']:.8f}\")\n",
    "    \n",
    "    print(f\"\\n  Unit Sphere Errors:\")\n",
    "    print(f\"    MSE: {errors_us['mse']:.8f}\")\n",
    "    print(f\"    MAE: {errors_us['mae']:.8f}\")\n",
    "    \n",
    "    # STEP 6 — Visualize reconstructed meshes\n",
    "    print(\"\\n[5] Creating reconstruction visualization...\")\n",
    "    visualize_reconstruction(original_vertices, recon_mm, recon_us, \n",
    "                           sample_name, sample_dir)\n",
    "    \n",
    "    # STEP 7 — Plot error per axis\n",
    "    print(\"\\n[6] Creating error plots...\")\n",
    "    plot_error_per_axis(errors_mm, errors_us, sample_name, sample_dir)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ Task 3 Completed: {sample_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"mesh\": sample_name,\n",
    "        \"mm_mse\": errors_mm['mse'],\n",
    "        \"mm_mae\": errors_mm['mae'],\n",
    "        \"us_mse\": errors_us['mse'],\n",
    "        \"us_mae\": errors_us['mae'],\n",
    "        \"mm_mse_x\": errors_mm['mse_axis'][0],\n",
    "        \"mm_mse_y\": errors_mm['mse_axis'][1],\n",
    "        \"mm_mse_z\": errors_mm['mse_axis'][2],\n",
    "        \"us_mse_x\": errors_us['mse_axis'][0],\n",
    "        \"us_mse_y\": errors_us['mse_axis'][1],\n",
    "        \"us_mse_z\": errors_us['mse_axis'][2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2db1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_meshes_task3():\n",
    "    \"\"\"Process all meshes for Task 3.\"\"\"\n",
    "    mesh_files = [f for f in os.listdir(MESH_DIR) if f.endswith('.obj')]\n",
    "    \n",
    "    if not mesh_files:\n",
    "        print(f\"No .obj files found in {MESH_DIR}/\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TASK 3: DEQUANTIZE, DENORMALIZE, AND MEASURE ERROR\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Found {len(mesh_files)} mesh file(s)\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for mesh_file in mesh_files:\n",
    "        mesh_path = os.path.join(MESH_DIR, mesh_file)\n",
    "        sample_name = os.path.splitext(mesh_file)[0]\n",
    "        \n",
    "        try:\n",
    "            result = process_mesh_task3(mesh_path, sample_name)\n",
    "            if result:\n",
    "                all_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ ERROR processing {mesh_file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # STEP 8 — Aggregate results\n",
    "    if all_results:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"AGGREGATE RESULTS - ALL MESHES\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Summary table\n",
    "        print(f\"\\n┌{'─'*30}┬{'─'*13}┬{'─'*13}┐\")\n",
    "        print(f\"│ {'Normalization Type':<28} │ {'Mean MSE':>11} │ {'Mean MAE':>11} │\")\n",
    "        print(f\"├{'─'*30}┼{'─'*13}┼{'─'*13}┤\")\n",
    "        \n",
    "        avg_mm_mse = np.mean([r['mm_mse'] for r in all_results])\n",
    "        avg_mm_mae = np.mean([r['mm_mae'] for r in all_results])\n",
    "        avg_us_mse = np.mean([r['us_mse'] for r in all_results])\n",
    "        avg_us_mae = np.mean([r['us_mae'] for r in all_results])\n",
    "        \n",
    "        print(f\"│ {'Min–Max':<28} │ {avg_mm_mse:>11.6f} │ {avg_mm_mae:>11.6f} │\")\n",
    "        print(f\"│ {'Unit Sphere':<28} │ {avg_us_mse:>11.6f} │ {avg_us_mae:>11.6f} │\")\n",
    "        print(f\"└{'─'*30}┴{'─'*13}┴{'─'*13}┘\\n\")\n",
    "        \n",
    "        # Save CSV\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            df = pd.DataFrame(all_results)\n",
    "            csv_path = os.path.join(OUTPUT_ROOT, \"summary_task3_errors.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\" Summary saved to: {csv_path}\")\n",
    "        except ImportError:\n",
    "            # Fallback without pandas\n",
    "            csv_path = os.path.join(OUTPUT_ROOT, \"summary_task3_errors.csv\")\n",
    "            with open(csv_path, 'w') as f:\n",
    "                f.write(\"mesh,mm_mse,mm_mae,us_mse,us_mae,mm_mse_x,mm_mse_y,mm_mse_z,us_mse_x,us_mse_y,us_mse_z\\n\")\n",
    "                for r in all_results:\n",
    "                    f.write(f\"{r['mesh']},{r['mm_mse']:.8f},{r['mm_mae']:.8f},\"\n",
    "                           f\"{r['us_mse']:.8f},{r['us_mae']:.8f},\"\n",
    "                           f\"{r['mm_mse_x']:.8f},{r['mm_mse_y']:.8f},{r['mm_mse_z']:.8f},\"\n",
    "                           f\"{r['us_mse_x']:.8f},{r['us_mse_y']:.8f},{r['us_mse_z']:.8f}\\n\")\n",
    "            print(f\" Summary saved to: {csv_path}\")\n",
    "        \n",
    "        # STEP 9 — Generate conclusion\n",
    "        conclusion = f\"\"\"\n",
    "{'='*70}\n",
    "TASK 3: RECONSTRUCTION ERROR ANALYSIS - CONCLUSION\n",
    "{'='*70}\n",
    "\n",
    "Summary Statistics:\n",
    "  Min-Max Normalization:\n",
    "    • Mean MSE: {avg_mm_mse:.8f}\n",
    "    • Mean MAE: {avg_mm_mae:.8f}\n",
    "  \n",
    "  Unit Sphere Normalization:\n",
    "    • Mean MSE: {avg_us_mse:.8f}\n",
    "    • Mean MAE: {avg_us_mae:.8f}\n",
    "\n",
    "Analysis:\n",
    "\"\"\"\n",
    "        \n",
    "        if avg_mm_mse < avg_us_mse:\n",
    "            diff_pct = ((avg_us_mse - avg_mm_mse) / avg_us_mse) * 100\n",
    "            conclusion += f\"\"\"\n",
    "  Min-Max normalization consistently resulted in lower reconstruction \n",
    "    errors (MSE ≈ {avg_mm_mse:.6f}) compared to Unit Sphere normalization.\n",
    "    \n",
    "  • Min-Max achieves {diff_pct:.1f}% lower MSE on average\n",
    "  • This suggests axis-independent scaling better preserves geometric detail\n",
    "    through quantization for this dataset\n",
    "\"\"\"\n",
    "        else:\n",
    "            diff_pct = ((avg_mm_mse - avg_us_mse) / avg_mm_mse) * 100\n",
    "            conclusion += f\"\"\"\n",
    "   Unit Sphere normalization resulted in lower reconstruction errors \n",
    "    (MSE ≈ {avg_us_mse:.6f}) compared to Min-Max normalization.\n",
    "    \n",
    "  • Unit Sphere achieves {diff_pct:.1f}% lower MSE on average\n",
    "  • Uniform isotropic scaling better preserves geometric detail through\n",
    "    quantization for this dataset\n",
    "\"\"\"\n",
    "        \n",
    "        # Per-axis analysis\n",
    "        avg_mm_mse_x = np.mean([r['mm_mse_x'] for r in all_results])\n",
    "        avg_mm_mse_y = np.mean([r['mm_mse_y'] for r in all_results])\n",
    "        avg_mm_mse_z = np.mean([r['mm_mse_z'] for r in all_results])\n",
    "        \n",
    "        axis_errors = [('X', avg_mm_mse_x), ('Y', avg_mm_mse_y), ('Z', avg_mm_mse_z)]\n",
    "        max_axis = max(axis_errors, key=lambda x: x[1])\n",
    "        \n",
    "        conclusion += f\"\"\"\n",
    "Per-Axis Error Analysis:\n",
    "  • {max_axis[0]}-axis showed slightly higher error (MSE: {max_axis[1]:.8f})\n",
    "  • This may be due to scale compression during normalization or\n",
    "    quantization bin distribution along this axis\n",
    "\n",
    "Quantization Quality:\n",
    "  • With {BINS} bins, both methods preserve geometric detail well\n",
    "  • Average reconstruction error is very low (< 0.001 for most meshes)\n",
    "  • Minimal perceptual distortion expected in reconstructed meshes\n",
    "\n",
    "Recommendation:\n",
    "  • For this dataset, {'Min-Max' if avg_mm_mse < avg_us_mse else 'Unit Sphere'} normalization is recommended\n",
    "  • Error levels are acceptable for most 3D processing applications\n",
    "  • Consider using 2048 bins for even higher fidelity if needed\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        \n",
    "        conclusion_path = os.path.join(OUTPUT_ROOT, \"task3_conclusion.txt\")\n",
    "        with open(conclusion_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(conclusion)\n",
    "        \n",
    "        print(conclusion)\n",
    "        print(f\"Conclusion saved to: {conclusion_path}\\n\")\n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"TASK 3 COMPLETE\")\n",
    "    print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3934b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_all_meshes_task3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
